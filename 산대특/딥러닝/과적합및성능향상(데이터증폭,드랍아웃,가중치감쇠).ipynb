{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gfgbLkc8Xebl"
      },
      "outputs": [],
      "source": [
        "# 드랍아웃의 성능향상을 측정\n",
        "# 교차검증으로 측정"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 확보\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct1H7n_8XnBr",
        "outputId": "c769ba45-f356-44c6-e48a-50df03d0dcfa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 표준화\n",
        "x_train = x_train.astype('float32')/ 255.0\n",
        "x_test = x_test.astype('float32')/ 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "J_xv2kHMYgKS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 매개변수\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "k = 5"
      ],
      "metadata": {
        "id": "3KwzAPXUZ6H6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.layers import *"
      ],
      "metadata": {
        "id": "8x6adSlyaqRR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-2cSNW7ilBZ",
        "outputId": "6eb52842-092d-4cad-81c3-0200e606c57f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 10), (10000, 32, 32, 3), (10000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 드랍아웃 비율에 따라서 교차 검증을 수행\n",
        "def cross_validation(dropout_rate:list):\n",
        "  accuracy = []\n",
        "  for train_index, val_index in KFold(k).split(x_train):\n",
        "    x_tr,x_val = x_train[train_index],x_train[val_index]\n",
        "    y_tr,y_val = y_train[train_index],y_train[val_index]\n",
        "    # 신경망 모델 설계 ccpd ccpd fl fc d fc\n",
        "    cnn = tf.keras.models.Sequential()\n",
        "    cnn.add(Conv2D(32,(3,3),activation='relu',input_shape = (32,32,3)))\n",
        "    cnn.add(Conv2D(32,(3,3),activation='relu'))\n",
        "    cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    cnn.add(Dropout(dropout_rate[0]))\n",
        "\n",
        "    cnn.add(Conv2D(64,(3,3),activation='relu'))\n",
        "    cnn.add(Conv2D(64,(3,3),activation='relu'))\n",
        "    cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    cnn.add(Dropout(dropout_rate[1]))\n",
        "\n",
        "    cnn.add(Flatten())\n",
        "\n",
        "    cnn.add(Dense(512,activation='relu'))\n",
        "    cnn.add(Dropout(dropout_rate[2]))\n",
        "    cnn.add(Dense(10,activation='softmax'))\n",
        "\n",
        "    #신경망 모델 학습하고 평가\n",
        "    cnn.compile(loss = tf.keras.losses.categorical_crossentropy,optimizer='adam', metrics=['accuracy'])\n",
        "    cnn.fit(x_tr,y_tr,batch_size=batch_size,epochs=epochs)\n",
        "    accuracy.append(cnn.evaluate(x_val,y_val)[1])\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "3mE4zfieaNpZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_without_dropout = cross_validation([0.0,0.0,0.0])\n",
        "acc_with_dropout = cross_validation([0.25,0.25,0.5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5L6VCU1eMph",
        "outputId": "9a219f6b-2613-4d33-d0dd-4922e6c41822"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 12s 10ms/step - loss: 1.5940 - accuracy: 0.4168\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2405 - accuracy: 0.5570\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0408 - accuracy: 0.6325\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.8971 - accuracy: 0.6866\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.7738 - accuracy: 0.7298\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6676 - accuracy: 0.7670\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5703 - accuracy: 0.8019\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.4805 - accuracy: 0.8331\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3786 - accuracy: 0.8679\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3018 - accuracy: 0.8961\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.9768 - accuracy: 0.7251\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 1.5486 - accuracy: 0.4369\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1717 - accuracy: 0.5840\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.9761 - accuracy: 0.6569\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.8242 - accuracy: 0.7133\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7021 - accuracy: 0.7548\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.5923 - accuracy: 0.7941\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4970 - accuracy: 0.8270\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3905 - accuracy: 0.8637\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3001 - accuracy: 0.8952\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2181 - accuracy: 0.9238\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1086 - accuracy: 0.7233\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.5896 - accuracy: 0.4206\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2097 - accuracy: 0.5696\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0185 - accuracy: 0.6389\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.8810 - accuracy: 0.6901\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.7701 - accuracy: 0.7309\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6562 - accuracy: 0.7715\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5580 - accuracy: 0.8069\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.4626 - accuracy: 0.8391\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3699 - accuracy: 0.8715\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2843 - accuracy: 0.9003\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9857 - accuracy: 0.7205\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.5869 - accuracy: 0.4182\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1650 - accuracy: 0.5879\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.9698 - accuracy: 0.6569\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.8352 - accuracy: 0.7056\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7215 - accuracy: 0.7476\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.6246 - accuracy: 0.7808\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.5293 - accuracy: 0.8126\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4358 - accuracy: 0.8480\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3534 - accuracy: 0.8754\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2781 - accuracy: 0.9022\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9594 - accuracy: 0.7294\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 1.5532 - accuracy: 0.4348\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1439 - accuracy: 0.5928\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.9611 - accuracy: 0.6615\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.8292 - accuracy: 0.7090\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7172 - accuracy: 0.7487\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6027 - accuracy: 0.7899\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4976 - accuracy: 0.8268\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4054 - accuracy: 0.8562\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3021 - accuracy: 0.8953\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2158 - accuracy: 0.9258\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0649 - accuracy: 0.7247\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 1.7227 - accuracy: 0.3667\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.3487 - accuracy: 0.5147\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1786 - accuracy: 0.5795\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.0559 - accuracy: 0.6283\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.9703 - accuracy: 0.6608\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.9094 - accuracy: 0.6817\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.8555 - accuracy: 0.6977\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.8092 - accuracy: 0.7143\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7765 - accuracy: 0.7280\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7373 - accuracy: 0.7386\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7444 - accuracy: 0.7386\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 1.6962 - accuracy: 0.3743\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.3147 - accuracy: 0.5282\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1468 - accuracy: 0.5927\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.0425 - accuracy: 0.6290\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.9524 - accuracy: 0.6644\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.8881 - accuracy: 0.6864\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.8298 - accuracy: 0.7069\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7783 - accuracy: 0.7256\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7453 - accuracy: 0.7386\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7077 - accuracy: 0.7498\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7150 - accuracy: 0.7531\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 1.7263 - accuracy: 0.3602\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.3547 - accuracy: 0.5091\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1843 - accuracy: 0.5781\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.0655 - accuracy: 0.6226\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.9744 - accuracy: 0.6574\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.8977 - accuracy: 0.6848\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.8425 - accuracy: 0.7051\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.8005 - accuracy: 0.7182\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7653 - accuracy: 0.7315\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7263 - accuracy: 0.7436\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6864 - accuracy: 0.7609\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 1.7255 - accuracy: 0.3573\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.3549 - accuracy: 0.5102\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1984 - accuracy: 0.5730\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.0758 - accuracy: 0.6156\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.9824 - accuracy: 0.6525\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.9230 - accuracy: 0.6727\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.8737 - accuracy: 0.6934\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.8265 - accuracy: 0.7095\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7908 - accuracy: 0.7224\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7560 - accuracy: 0.7336\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7552 - accuracy: 0.7395\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 1.7217 - accuracy: 0.3619\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.3441 - accuracy: 0.5149\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1783 - accuracy: 0.5746\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.0660 - accuracy: 0.6232\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.9716 - accuracy: 0.6566\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.9042 - accuracy: 0.6829\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.8560 - accuracy: 0.6980\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.8042 - accuracy: 0.7167\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7618 - accuracy: 0.7327\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7298 - accuracy: 0.7444\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7366 - accuracy: 0.7433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(acc_without_dropout).mean(), np.array( acc_with_dropout).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Puy0LbuOh8FP",
        "outputId": "99fa4ffd-3757-4ee6-9d14-3bbae4a97f27"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7245999813079834, 0.7470800042152405)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 박스플롯으로 정확률 표시\n",
        "import matplotlib.pyplot as plt\n",
        "plt.boxplot([acc_without_dropout,acc_with_dropout],labels = ['acc_without_dropout','acc_with_dropout'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "LGs5EC73lALn",
        "outputId": "b6dc8842-754d-416d-cf54-5fa9246a9c53"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'whiskers': [<matplotlib.lines.Line2D at 0x7fc7ee5a62d0>,\n",
              "  <matplotlib.lines.Line2D at 0x7fc7ee5a6810>,\n",
              "  <matplotlib.lines.Line2D at 0x7fc7ee5b6990>,\n",
              "  <matplotlib.lines.Line2D at 0x7fc7ee5b6e90>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7fc7ee5a6d50>,\n",
              "  <matplotlib.lines.Line2D at 0x7fc7ee5af2d0>,\n",
              "  <matplotlib.lines.Line2D at 0x7fc7ee5be410>,\n",
              "  <matplotlib.lines.Line2D at 0x7fc7ee5be950>],\n",
              " 'boxes': [<matplotlib.lines.Line2D at 0x7fc7ee618c90>,\n",
              "  <matplotlib.lines.Line2D at 0x7fc7ee5b6450>],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7fc7ee5af850>,\n",
              "  <matplotlib.lines.Line2D at 0x7fc7ee5bee90>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7fc7ee5afd90>,\n",
              "  <matplotlib.lines.Line2D at 0x7fc7ee5c4410>],\n",
              " 'means': []}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 감쇠 weight decay : 성능을 유지한 채로 가중치 크기를 낮추는 규제 기법"
      ],
      "metadata": {
        "id": "sSHAePuZlfAX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "wdD5Vc5AmIZ3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능평가.. \n",
        "# 검증... 교차검증\n",
        "# 제거 조사 ablation study  - 여러선택사항중에서 하나씩 배고 성능을 측정"
      ],
      "metadata": {
        "id": "YHm5XnkAmLGX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 재활용 가능한 코드로 만들어서 테스트\n",
        "# 마지막 출력층에.. 적용..\n",
        "cnn.add(Dense(10,activation='softmax', kernel_regularizer = regularizers.l1(0.01)))\n",
        "cnn.add(Dense(10,activation='softmax', kernel_regularizer = regularizers.l2(0.01)))"
      ],
      "metadata": {
        "id": "nZl617DsnxJo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}